{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Multilayer Perceptron Network</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set(style='ticks', palette = 'Spectral', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "tf.set_random_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>subred_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.022503</td>\n",
       "      <td>9.263481</td>\n",
       "      <td>7.196661</td>\n",
       "      <td>0.713737</td>\n",
       "      <td>-10.198532</td>\n",
       "      <td>-5.373705</td>\n",
       "      <td>6.329010</td>\n",
       "      <td>-11.324772</td>\n",
       "      <td>22.767520</td>\n",
       "      <td>6.896969</td>\n",
       "      <td>...</td>\n",
       "      <td>3.639935</td>\n",
       "      <td>-10.124123</td>\n",
       "      <td>13.274714</td>\n",
       "      <td>-8.389603</td>\n",
       "      <td>-6.505627</td>\n",
       "      <td>6.343185</td>\n",
       "      <td>-17.560234</td>\n",
       "      <td>-2.442932</td>\n",
       "      <td>3.079132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.323867</td>\n",
       "      <td>7.722980</td>\n",
       "      <td>12.684483</td>\n",
       "      <td>32.433552</td>\n",
       "      <td>-16.988693</td>\n",
       "      <td>-10.869745</td>\n",
       "      <td>4.093761</td>\n",
       "      <td>-28.068019</td>\n",
       "      <td>25.313713</td>\n",
       "      <td>20.590340</td>\n",
       "      <td>...</td>\n",
       "      <td>8.180832</td>\n",
       "      <td>-23.305218</td>\n",
       "      <td>0.471176</td>\n",
       "      <td>-14.555885</td>\n",
       "      <td>-25.838142</td>\n",
       "      <td>2.277317</td>\n",
       "      <td>-25.614525</td>\n",
       "      <td>15.118515</td>\n",
       "      <td>2.317825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.467317</td>\n",
       "      <td>113.915773</td>\n",
       "      <td>65.519438</td>\n",
       "      <td>245.179375</td>\n",
       "      <td>-94.565128</td>\n",
       "      <td>-109.999386</td>\n",
       "      <td>93.734236</td>\n",
       "      <td>-87.885499</td>\n",
       "      <td>257.730162</td>\n",
       "      <td>121.020763</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.143604</td>\n",
       "      <td>-146.690353</td>\n",
       "      <td>34.986722</td>\n",
       "      <td>-84.497543</td>\n",
       "      <td>-77.428837</td>\n",
       "      <td>90.276260</td>\n",
       "      <td>-132.698345</td>\n",
       "      <td>64.056031</td>\n",
       "      <td>158.318733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.672150</td>\n",
       "      <td>8.860280</td>\n",
       "      <td>6.773788</td>\n",
       "      <td>5.557095</td>\n",
       "      <td>-13.995350</td>\n",
       "      <td>-1.298798</td>\n",
       "      <td>14.855133</td>\n",
       "      <td>-13.880474</td>\n",
       "      <td>26.359550</td>\n",
       "      <td>16.415405</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.279045</td>\n",
       "      <td>-10.628357</td>\n",
       "      <td>10.426218</td>\n",
       "      <td>-11.863808</td>\n",
       "      <td>-10.780058</td>\n",
       "      <td>0.959249</td>\n",
       "      <td>-18.345068</td>\n",
       "      <td>6.968060</td>\n",
       "      <td>6.299683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.122070</td>\n",
       "      <td>-0.461533</td>\n",
       "      <td>-1.217285</td>\n",
       "      <td>2.936523</td>\n",
       "      <td>-2.079285</td>\n",
       "      <td>2.565628</td>\n",
       "      <td>3.502319</td>\n",
       "      <td>-0.293793</td>\n",
       "      <td>4.122253</td>\n",
       "      <td>1.102203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417969</td>\n",
       "      <td>-0.977966</td>\n",
       "      <td>-1.018799</td>\n",
       "      <td>1.823914</td>\n",
       "      <td>-2.710815</td>\n",
       "      <td>0.975128</td>\n",
       "      <td>-4.760040</td>\n",
       "      <td>-0.759163</td>\n",
       "      <td>0.799683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2           3          4           5  \\\n",
       "0   1.022503    9.263481   7.196661    0.713737 -10.198532   -5.373705   \n",
       "1  -0.323867    7.722980  12.684483   32.433552 -16.988693  -10.869745   \n",
       "2  77.467317  113.915773  65.519438  245.179375 -94.565128 -109.999386   \n",
       "3   0.672150    8.860280   6.773788    5.557095 -13.995350   -1.298798   \n",
       "4  -0.122070   -0.461533  -1.217285    2.936523  -2.079285    2.565628   \n",
       "\n",
       "           6          7           8           9  ...        291         292  \\\n",
       "0   6.329010 -11.324772   22.767520    6.896969  ...   3.639935  -10.124123   \n",
       "1   4.093761 -28.068019   25.313713   20.590340  ...   8.180832  -23.305218   \n",
       "2  93.734236 -87.885499  257.730162  121.020763  ... -58.143604 -146.690353   \n",
       "3  14.855133 -13.880474   26.359550   16.415405  ...  -5.279045  -10.628357   \n",
       "4   3.502319  -0.293793    4.122253    1.102203  ...  -0.417969   -0.977966   \n",
       "\n",
       "         293        294        295        296         297        298  \\\n",
       "0  13.274714  -8.389603  -6.505627   6.343185  -17.560234  -2.442932   \n",
       "1   0.471176 -14.555885 -25.838142   2.277317  -25.614525  15.118515   \n",
       "2  34.986722 -84.497543 -77.428837  90.276260 -132.698345  64.056031   \n",
       "3  10.426218 -11.863808 -10.780058   0.959249  -18.345068   6.968060   \n",
       "4  -1.018799   1.823914  -2.710815   0.975128   -4.760040  -0.759163   \n",
       "\n",
       "          299  subred_num  \n",
       "0    3.079132           0  \n",
       "1    2.317825           0  \n",
       "2  158.318733           0  \n",
       "3    6.299683           0  \n",
       "4    0.799683           0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dummy variables for outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>subred_num</th>\n",
       "      <th>sub__0</th>\n",
       "      <th>sub__1</th>\n",
       "      <th>sub__2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.022503</td>\n",
       "      <td>9.263481</td>\n",
       "      <td>7.196661</td>\n",
       "      <td>0.713737</td>\n",
       "      <td>-10.198532</td>\n",
       "      <td>-5.373705</td>\n",
       "      <td>6.329010</td>\n",
       "      <td>-11.324772</td>\n",
       "      <td>22.767520</td>\n",
       "      <td>6.896969</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.389603</td>\n",
       "      <td>-6.505627</td>\n",
       "      <td>6.343185</td>\n",
       "      <td>-17.560234</td>\n",
       "      <td>-2.442932</td>\n",
       "      <td>3.079132</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.323867</td>\n",
       "      <td>7.722980</td>\n",
       "      <td>12.684483</td>\n",
       "      <td>32.433552</td>\n",
       "      <td>-16.988693</td>\n",
       "      <td>-10.869745</td>\n",
       "      <td>4.093761</td>\n",
       "      <td>-28.068019</td>\n",
       "      <td>25.313713</td>\n",
       "      <td>20.590340</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.555885</td>\n",
       "      <td>-25.838142</td>\n",
       "      <td>2.277317</td>\n",
       "      <td>-25.614525</td>\n",
       "      <td>15.118515</td>\n",
       "      <td>2.317825</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.467317</td>\n",
       "      <td>113.915773</td>\n",
       "      <td>65.519438</td>\n",
       "      <td>245.179375</td>\n",
       "      <td>-94.565128</td>\n",
       "      <td>-109.999386</td>\n",
       "      <td>93.734236</td>\n",
       "      <td>-87.885499</td>\n",
       "      <td>257.730162</td>\n",
       "      <td>121.020763</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.497543</td>\n",
       "      <td>-77.428837</td>\n",
       "      <td>90.276260</td>\n",
       "      <td>-132.698345</td>\n",
       "      <td>64.056031</td>\n",
       "      <td>158.318733</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.672150</td>\n",
       "      <td>8.860280</td>\n",
       "      <td>6.773788</td>\n",
       "      <td>5.557095</td>\n",
       "      <td>-13.995350</td>\n",
       "      <td>-1.298798</td>\n",
       "      <td>14.855133</td>\n",
       "      <td>-13.880474</td>\n",
       "      <td>26.359550</td>\n",
       "      <td>16.415405</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.863808</td>\n",
       "      <td>-10.780058</td>\n",
       "      <td>0.959249</td>\n",
       "      <td>-18.345068</td>\n",
       "      <td>6.968060</td>\n",
       "      <td>6.299683</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.122070</td>\n",
       "      <td>-0.461533</td>\n",
       "      <td>-1.217285</td>\n",
       "      <td>2.936523</td>\n",
       "      <td>-2.079285</td>\n",
       "      <td>2.565628</td>\n",
       "      <td>3.502319</td>\n",
       "      <td>-0.293793</td>\n",
       "      <td>4.122253</td>\n",
       "      <td>1.102203</td>\n",
       "      <td>...</td>\n",
       "      <td>1.823914</td>\n",
       "      <td>-2.710815</td>\n",
       "      <td>0.975128</td>\n",
       "      <td>-4.760040</td>\n",
       "      <td>-0.759163</td>\n",
       "      <td>0.799683</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2           3          4           5  \\\n",
       "0   1.022503    9.263481   7.196661    0.713737 -10.198532   -5.373705   \n",
       "1  -0.323867    7.722980  12.684483   32.433552 -16.988693  -10.869745   \n",
       "2  77.467317  113.915773  65.519438  245.179375 -94.565128 -109.999386   \n",
       "3   0.672150    8.860280   6.773788    5.557095 -13.995350   -1.298798   \n",
       "4  -0.122070   -0.461533  -1.217285    2.936523  -2.079285    2.565628   \n",
       "\n",
       "           6          7           8           9  ...        294        295  \\\n",
       "0   6.329010 -11.324772   22.767520    6.896969  ...  -8.389603  -6.505627   \n",
       "1   4.093761 -28.068019   25.313713   20.590340  ... -14.555885 -25.838142   \n",
       "2  93.734236 -87.885499  257.730162  121.020763  ... -84.497543 -77.428837   \n",
       "3  14.855133 -13.880474   26.359550   16.415405  ... -11.863808 -10.780058   \n",
       "4   3.502319  -0.293793    4.122253    1.102203  ...   1.823914  -2.710815   \n",
       "\n",
       "         296         297        298         299  subred_num  sub__0  sub__1  \\\n",
       "0   6.343185  -17.560234  -2.442932    3.079132           0       1       0   \n",
       "1   2.277317  -25.614525  15.118515    2.317825           0       1       0   \n",
       "2  90.276260 -132.698345  64.056031  158.318733           0       1       0   \n",
       "3   0.959249  -18.345068   6.968060    6.299683           0       1       0   \n",
       "4   0.975128   -4.760040  -0.759163    0.799683           0       1       0   \n",
       "\n",
       "   sub__2  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.join(pd.get_dummies(df['subred_num'], prefix='sub_'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x2371c757828>,\n",
       "  <matplotlib.patches.Wedge at 0x2371c767278>,\n",
       "  <matplotlib.patches.Wedge at 0x2371c767c88>],\n",
       " [Text(0.3260709086284462, 1.0505606896063737, '1'),\n",
       "  Text(-0.9185370500890002, -0.6052187105615603, '0'),\n",
       "  Text(0.8502974186600647, -0.697849768804168, '2')],\n",
       " [Text(0.17785685925187972, 0.5730331034216584, '40.4%'),\n",
       "  Text(-0.5010202091394546, -0.33011929666994194, '37.7%'),\n",
       "  Text(0.4637985919963989, -0.3806453284386371, '21.9%')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_values = df['subred_num'].value_counts()\n",
    "sizes = type_values.values\n",
    "labels = type_values.index.values\n",
    "plt.pie(sizes, labels=labels, shadow=True, autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature vec dataset\n",
    "X = df.iloc[:,:300]\n",
    "y = df.iloc[:,-3:]\n",
    "y.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates Multilayer perceptron network adding multiple layers<br>\n",
    "https://skymind.ai/wiki/multilayer-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases, keep_probs):\n",
    "    #hiddent layer 1\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_1 = tf.nn.dropout(layer_1, keep_probs)\n",
    "    #hidden layer 2\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters like weights and biases for neural network. Basically weights and biases will be two dimensional matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\ms\\python workspace\\untitled folder 2\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "n_hidden_1 = 64 #number of neurons in first hidden layer\n",
    "n_hidden_2 = 64 #number of neurons in second hidden layer\n",
    "n_input = X_train.shape[1]\n",
    "n_classes = 3\n",
    "\n",
    "weights = {\n",
    "    'h1' : tf.Variable(tf.random.normal([n_input, n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.random.normal([n_hidden_1,n_hidden_2])),\n",
    "    'out' : tf.Variable(tf.random.normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random.normal([n_hidden_1])),\n",
    "    'b2' : tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out' : tf.Variable(tf.random.normal([n_classes]))\n",
    "}\n",
    "\n",
    "keep_probs = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_epochs = 200\n",
    "display_step = 25\n",
    "batch_size = 32\n",
    "\n",
    "#None because number of rows could be anything(matrix multiplication would be [ ,3]*[3,32], no of columns in first and \n",
    "#no of rows in second matrix should be same..3 in this case\n",
    "x = tf.placeholder(\"float\", [None, n_input]) \n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Could also manipulate with sigmomoid\n",
    "#predictions = multilayer_perceptron(x, weights, biases, keep_probs)\n",
    "#cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-7b4a641f1633>:5: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-11-fd1c5877ce2b>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#softmax entropy\n",
    "predictions = multilayer_perceptron(x, weights, biases, keep_probs)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost= 8921.188714600\n",
      "Epoch:  0026 cost= 799.661475754\n",
      "Epoch:  0051 cost= 207.061592329\n",
      "Epoch:  0076 cost= 25.568273021\n",
      "Epoch:  0101 cost= 7.108320580\n",
      "Epoch:  0126 cost= 9.911028829\n",
      "Epoch:  0151 cost= 3.079650465\n",
      "Epoch:  0176 cost= 3.004612423\n",
      "Optimization finished!\n",
      "Accuracy: 0.4265241\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(train_epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(len(X_train)/batch_size)\n",
    "        x_batches = np.array_split(X_train, total_batch)\n",
    "        y_batches = np.array_split(y_train, total_batch)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = x_batches[i], y_batches[i]\n",
    "            \n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                      y: batch_y, \n",
    "                                                      keep_probs: 0.8})\n",
    "            \n",
    "            avg_cost += c / total_batch\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch: \", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization finished!\")\n",
    "    #print(predictions)\n",
    "    #print(y)\n",
    "    #val = tf.nn.sigmoid(predictions)\n",
    "    #correct_prediction = tf.equal(tf.round(val), y)\n",
    "    correct_prediction = tf.equal(tf.argmax(predictions,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x:X_test, y:y_test, keep_probs:1.00}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnetwork",
   "language": "python",
   "name": "neuralnetwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
